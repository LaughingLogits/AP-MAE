{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bcf1224-40eb-48cd-b528-b2f7dfdad584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir Database #Only run once, makes a folder where the h5py database is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b332fe4-996d-4f54-922e-8355caed189b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is required to import the APMAE model from the other directory\n",
    "import sys, os\n",
    "path2add = os.path.normpath(os.path.abspath(os.path.join(os.path.dirname('./run.ipynb'), os.path.pardir, 'Model')))\n",
    "if (not (path2add in sys.path)) :\n",
    "    sys.path.append(path2add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c11b6-fcfd-4bf4-a49e-c050ab8566ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our code\n",
    "from DataUtil.DataLoader import IterableAttentionLoader\n",
    "from DataUtil.AttentionData import AttentionData\n",
    "from ap_mae import APMAE\n",
    "\n",
    "#Imported packages\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "#We recommend to use the cuml package for quicker computation if a decent gpu is available, can be replaced by the corresponding sklearn packages\n",
    "from cuml import UMAP\n",
    "from cuml import HDBSCAN\n",
    "from cuml.metrics.pairwise_distances import pairwise_distances\n",
    "\n",
    "\n",
    "#for classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635abcfe-6dec-4a0d-a1a6-854bfaf52684",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95bfb6-94dd-4373-8011-f81f1bb10fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = '3B' #Set the size of the target model here. 3B, 7B or 15B\n",
    "            #3B requires 2TB of storage\n",
    "            #7B requires 3.5TB of storage\n",
    "            #15B requires 5.5TB of storage\n",
    "\n",
    "db_name = \"reproduction_{}\".format(size)\n",
    "target_model_name = 'bigcode/starcoder2-{}'.format(size.lower())\n",
    "encoding_model_name = 'LaughingLogits/AP-MAE-SC2-{}'.format(size)\n",
    "dataset_name = 'LaughingLogits/Stackless_Java_V2'\n",
    "split = 'test'\n",
    "\n",
    "device = 'cpu'\n",
    "languages = ['java']\n",
    "\n",
    "tasks = ['noise', 'random', 'identifiers', 'boolean_literals', 'numeric_literals', 'string_literals', 'boolean_operators', 'mathematical_operators', 'assignment_operators', 'eol', 'closing_bracket']\n",
    "\n",
    "samples_per_task = 1000\n",
    "context_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd044f9b-ddad-4460-abf0-7f0c9afd25c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These can be replaced with a list of keys, but we used all values in our investigation\n",
    "# e.g. incorrect java predicitions for the eol task, all heads from layer 4 and 7\n",
    "# langs = ['java']\n",
    "# corrects = ['incorrect']\n",
    "# querys = ['eol']\n",
    "# layers = ['4','7']\n",
    "# heads = \"*\"\n",
    "langs = \"*\"\n",
    "corrects = \"*\"\n",
    "querys = \"*\"\n",
    "layers = \"*\"\n",
    "heads = \"*\"\n",
    "\n",
    "if size =='3B':\n",
    "    n_layers, n_heads = 30, 24\n",
    "elif size =='7B':\n",
    "    n_layers, n_heads = 32, 36\n",
    "elif size =='15B':\n",
    "    n_layers, n_heads = 40, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a3422-edcf-4433-bcb3-bb5c739a15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = AutoModelForCausalLM.from_pretrained(target_model_name, device_map=\"auto\")\n",
    "encoding_model = APMAE.from_pretrained(pretrained_model_name_or_path=encoding_model_name)\n",
    "attention_data = AttentionData(target_model.config, tasks, languages, db_name)\n",
    "attention_loader = IterableAttentionLoader(dataset_name, samples_per_task, context_length, tasks, languages[0], target_model_name, False, target_model, device, split, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7edac-1db1-4ee6-8710-0804b0a5f1cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate patterns and encode - Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ca6d3-e88e-4bdc-8fb3-98c009288c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this and all patterns are saved, it takes up alot of storage (up to 5.5TB per 10,000 samples).\n",
    "attention_data.generate_patterns(attention_loader)\n",
    "attention_data.encode(encoding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdfa23-968b-4721-bad4-6934b5b17c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this and it wont save the actual pattern, only the encoding (up to 750GB per 100,000 samples) 10 is the btachsize for the encoder.\n",
    "attention_data.generate_and_encode(attention_loader, encoding_model, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcb7a0-6ff5-4aeb-ba60-f08a1f40bc9e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd76f6-2f38-4760-91f0-1c2b9767e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73494749-485e-4746-969f-6bf02cbd39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for l in range(n_layers):\n",
    "    for h in range(n_heads):\n",
    "        X = attention_data.data.get_grouped_samples(langs, corrects, querys, [l], [h], 'enc_cls')\n",
    "\n",
    "\n",
    "        #We add jitter, only where the values match, if it fails 3 times, we add jitter everywhere\n",
    "        jitter_val = 1e-3\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                X = jitter(X, jitter = jitter_val)\n",
    "                X = cp.asarray(X)\n",
    "                # The UMAP model, with the hyperparameters we used\n",
    "                umap_model = UMAP(\n",
    "                    n_components=8,\n",
    "                    n_neighbors=20,\n",
    "                    min_dist=0.05,\n",
    "                    metric='cosine'\n",
    "                )\n",
    "                X_embed = umap_model.fit_transform(X)\n",
    "                break #Exit retry loop if it worked\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed\")\n",
    "                print(jitter_val)\n",
    "                jitter_val = 5*jitter_val\n",
    "                if attempt == 2:\n",
    "                    print(\"selective jitter failed, jittering everywhere\")\n",
    "                    X = cp.asarray(X.get() + 1e-3 * np.random.randn(X.shape[0], X.shape[1]))\n",
    "                        umap_model = UMAP(\n",
    "                        n_components=8,\n",
    "                        min_dist=0.05,\n",
    "                        n_neighbors=20,\n",
    "                        metric='cosine'\n",
    "                    )\n",
    "                    X_embed = umap_model.fit_transform(X)\n",
    "                    \n",
    "        # The HDBSCAN model with the hyperparameters we used.\n",
    "        hdbscan_model = HDBSCAN(min_samples=20, min_cluster_size=25, allow_single_cluster=True) \n",
    "        labels = hdbscan_model.fit_predict(X_embed.get())\n",
    "    \n",
    "        #Save the clusters in our H5PY Database\n",
    "        attention_data.data.write_grouped_samples(langs, corrects, querys, [l], [h], \"class_cls\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0087c-88a6-4427-889d-897c3fcbe26c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57304f9a-096b-4e25-8c0c-9178f8ca4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical value features to pass to CatBoost\n",
    "col_names = []\n",
    "for l in range(40):\n",
    "    for h in range(48):\n",
    "        col_names.append(f'l{l}h{h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9056e-490c-4aa6-8f06-dbf890f22ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['random', 'identifiers', 'boolean_literals', 'numeric_literals', 'string_literals', 'boolean_operators', 'mathematical_operators', 'assignment_operators', 'eol', 'closing_bracket']\n",
    "\n",
    "for t in tasks:\n",
    "    for l in tqdm(range(n_layers)):\n",
    "        for h in range(n_heads):\n",
    "            df[f'l{l}h{h}'] = attention_data.data.get_grouped_samples(langs, corrects, querys, [l], [h], 'enc_cls')\n",
    "\n",
    "    # returns the labels correct, or incorrect for each prediction\n",
    "    y = attention_data.data.get_grouped_clusters(langs, corrects, querys, layers, heads, 'enc_cls', True, False, True, True, True) \n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=6,\n",
    "        learning_rate=0.1,\n",
    "        loss_function='Logloss',\n",
    "        cat_features=col_names,\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=25,\n",
    "        eval_fraction=0.1,\n",
    "        task_type='GPU', #remove if no GPU is available\n",
    "        devices='0'\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    #Evaluate the classification\n",
    "    cmd = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "    plt.show()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{t} accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "    ##### SHAP VALUES #####\n",
    "    pool = Pool(X_test, y_test, cat_features=col_names)\n",
    "    # Get SHAP values from CatBoost\n",
    "    shap_values = model.get_feature_importance(pool, type='ShapValues')\n",
    "    \n",
    "    # Extract only per-feature SHAP values\n",
    "    feature_shap_values = shap_values[:, 1:]\n",
    "    \n",
    "    # Build a shap.Explanation object\n",
    "    expl = shap.Explanation(\n",
    "        values=feature_shap_values,\n",
    "        base_values=shap_values[:, 0],\n",
    "        data=X_test.values,\n",
    "        feature_names=X_test.columns.tolist()\n",
    "    )\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
